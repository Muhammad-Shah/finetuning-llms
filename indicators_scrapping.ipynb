{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3376193b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (4.23.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: bs4 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: pyperclip in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (1.9.0)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from selenium) (0.26.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from selenium) (2024.7.4)\n",
      "Requirement already satisfied: typing_extensions~=4.9.0 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: websocket-client==1.8.0 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: requests in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from webdriver-manager) (2.32.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\pc\\miniconda3\\envs\\myenv\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.4\n"
     ]
    }
   ],
   "source": [
    "%pip install selenium numpy bs4 pandas webdriver-manager pyperclip tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c1da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pyperclip\n",
    "import json\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa60ae5",
   "metadata": {},
   "source": [
    "# My CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2af8a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading urls of each  indicator\n",
    "import pandas as pd \n",
    "df_links=pd.read_csv(\"indicators_data_links.csv\")\n",
    "all_links=list(df_links.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f022e6c4-b352-44b8-93e3-a73b57260f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(df_links.duplicated().sum())\n",
    "\n",
    "# Remove duplicates\n",
    "df_links = df_links.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6aa3491",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "# Close the WebDriver\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a608de01",
   "metadata": {},
   "source": [
    "## Store In JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fab2ef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return links of indicatiors in each page \n",
    "import time\n",
    "def indi_detail(url):\n",
    "    # driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    time.sleep(0.9)\n",
    "    \n",
    "    try:\n",
    "        name = driver.find_element(By.TAG_NAME, \"h1\")\n",
    "        time.sleep(0.3)\n",
    "        description = driver.find_element(By.CSS_SELECTOR, \"div.tv-chart-view__description.selectable\")\n",
    "        time.sleep(0.3)\n",
    "        copy_button = driver.find_element(By.CSS_SELECTOR, \".light-button-bYDQcOkp.no-content-bYDQcOkp.with-start-icon-bYDQcOkp.variant-quiet-primary-bYDQcOkp.color-gray-bYDQcOkp.size-xsmall-bYDQcOkp.typography-regular14px-bYDQcOkp\")\n",
    "        name = name.text if name else None\n",
    "        description = description.text if description else None\n",
    "        copy_button = driver.find_element(By.CSS_SELECTOR, \".light-button-bYDQcOkp.no-content-bYDQcOkp.with-start-icon-bYDQcOkp.variant-quiet-primary-bYDQcOkp.color-gray-bYDQcOkp.size-xsmall-bYDQcOkp.typography-regular14px-bYDQcOkp\")\n",
    "        copy_button.click()\n",
    "        time.sleep(0.3)                      # Adjust if necessary\n",
    "        code = pyperclip.paste()\n",
    "        code = code if code else None\n",
    "    except Exception as e:\n",
    "        name, description, code = None, None, None\n",
    "        return {\n",
    "        \"Indicator Name\": name,\n",
    "        \"Indicator Description\": description,\n",
    "        \"Indicator Code\": code\n",
    "    }\n",
    "    return {\n",
    "        \"Indicator Name\": name,\n",
    "        \"Indicator Description\": description,\n",
    "        \"Indicator Code\": code\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66de2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicator1=all_links[7200:8999]  # DONE\n",
    "indicator1=all_links[5000:7200]\n",
    "# Initialize the index from where to resume scraping\n",
    "resume_index = 0\n",
    "indicators_data = []\n",
    "links_not_scrapped = {'links': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6937222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [06:57,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [11:54,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [12:56, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [18:11,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [19:17,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [20:49, 10.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [21:07, 12.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [21:16, 11.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112it [22:50, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "119it [24:08, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120it [24:14,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "130it [26:11, 11.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "142it [28:10,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "147it [29:30, 15.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [31:53,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "158it [32:04, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171it [34:12,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172it [34:17,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [36:12,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "197it [38:15,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "208it [39:33,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "229it [42:03,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "234it [42:34,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "258it [45:21,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "279it [48:10,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "284it [49:01, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "308it [53:19, 11.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered in none block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "312it [55:07, 10.60s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load the resume index if available\n",
    "try:\n",
    "    with open('resume_index.txt', 'r') as file:\n",
    "        resume_index = int(file.read().strip())\n",
    "        print(resume_index)\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "try:\n",
    "    with open('data.json', 'r') as f:\n",
    "        indicators_data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "# Initialize the Chrome driver outside the loop\n",
    "#driver = webdriver.Chrome()\n",
    "\n",
    "for i, link in tqdm.tqdm(enumerate(indicator1[resume_index:], resume_index)):\n",
    "    # Scrape data for the current link\n",
    "    scrap_data = indi_detail(link)\n",
    "        \n",
    "    # If scraping is successful, update the resume_index\n",
    "    if scrap_data['Indicator Name'] or scrap_data['Indicator Description'] or scrap_data['Indicator Code']:\n",
    "        resume_index = i + 1\n",
    "        # Append the new data to the existing data\n",
    "        indicators_data.append(scrap_data)\n",
    "    else:\n",
    "        links_not_scrapped['links'].append(link)\n",
    "\n",
    "    # Save the resume_index periodically, e.g., every 10 links\n",
    "    if i % 50 == 0:\n",
    "        with open('resume_index.txt', 'w') as file:\n",
    "            file.write(str(resume_index))\n",
    "        \n",
    "        # Write the updated data to the JSON file\n",
    "        with open('dataTest.json', 'w') as f:\n",
    "            json.dump(indicators_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9795b513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final save after the loop\n",
    "with open('resume_index.txt', 'w') as file:\n",
    "    file.write(str(resume_index))\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(indicators_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5a1e022-2a36-4349-8cb7-6f84e1ab228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unscrapped_links = pd.read_csv('links_not_scrapped.csv')\n",
    "links_not_scrapped_df = pd.DataFrame(data=links_not_scrapped)\n",
    "links_not_scrapped_df = pd.concat([links_not_scrapped_df, unscrapped_links], axis=0)\n",
    "links_not_scrapped_df.to_csv('links_not_scrapped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4890e0",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">END</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eaead6-3454-4436-93ec-8fa862504b82",
   "metadata": {},
   "source": [
    "### Some Links Doesn't Scrap So We need to Scrap Those Links as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81ce6a65-ff1e-4253-aee0-eb9cf7defd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the index from where to resume scraping\n",
    "resume_index = 0\n",
    "indicators_data = []\n",
    "links_not_scrapped = {'links': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e72afe2-38ab-4b83-aa53-b2c8a209edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv('links_not_scrapped.csv')\n",
    "links_to_scrap = list(links.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c46569a-c8dc-45f8-af4b-2734be4b6ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:45, 11.40s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load the resume index if available\n",
    "try:\n",
    "    with open('resume_index.txt', 'r') as file:\n",
    "        resume_index = int(file.read().strip())\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "try:\n",
    "    with open('data.json', 'r') as f:\n",
    "        indicators_data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "# Initialize the Chrome driver outside the loop\n",
    "# driver = webdriver.Chrome()\n",
    "\n",
    "for i, link in tqdm.tqdm(enumerate(links_to_scrap[resume_index:], resume_index)):\n",
    "    # Scrape data for the current link\n",
    "    scrap_data = indi_detail(link)\n",
    "\n",
    "    # If scraping is successful, update the resume_index\n",
    "    if scrap_data['Indicator Name']:\n",
    "        resume_index = i + 1\n",
    "        # Append the new data to the existing data\n",
    "        indicators_data.append(scrap_data)\n",
    "    else:\n",
    "        links_not_scrapped['links'].append(link)\n",
    "\n",
    "    # Save the resume_index periodically, e.g., every 10 links\n",
    "    if i % 50 == 0:\n",
    "        with open('resume_index.txt', 'w') as file:\n",
    "            file.write(str(resume_index))\n",
    "        \n",
    "        # Write the updated data to the JSON file\n",
    "        with open('dataTest.json', 'w') as f:\n",
    "            json.dump(indicators_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b6c1604-ff17-4aa4-bcca-111e7623b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final save after the loop\n",
    "with open('resume_index.txt', 'w') as file:\n",
    "    file.write(str(resume_index))\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(indicators_data, f, indent=4)\n",
    "\n",
    "links_not_scrapped_df = pd.DataFrame(data=links_not_scrapped)\n",
    "links_not_scrapped_df.to_csv('links_not_scrapped.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65db95a9-ce81-4d2b-b1b2-471796578f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e285e8a-fbfd-4256-97ed-33bf0d9dd5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[165, 368, 394, 1191]\n"
     ]
    }
   ],
   "source": [
    "with open('data.json', 'r') as f:\n",
    "    part_one = json.load(f)\n",
    "\n",
    "index_none = [i for i, data in enumerate(part_one) if any(val is None for val in data.values())]\n",
    "\n",
    "print(index_none)\n",
    "\n",
    "links_to_scrap = [all_links[i] for i in index_none]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f421030-dc8a-4492-b174-7b19a2f49243",
   "metadata": {},
   "source": [
    "<h3> Concatenate Datasets </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "014fd41d-fbce-42f2-bf35-2a5cc0759dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSON files\n",
    "with open('Data/data_part5.json', 'r') as f:\n",
    "    data1 = json.load(f)\n",
    "\n",
    "with open('Data/part1.json', 'r') as f:\n",
    "    data2 = json.load(f)\n",
    "\n",
    "with open('Data/part1.json', 'r') as f:\n",
    "    data3 = json.load(f)\n",
    "\n",
    "# Combine the data\n",
    "# Combine the data by concatenating the lists\n",
    "combined_data = data1 + data2 + data3\n",
    "\n",
    "# If they are lists and you want to concatenate them, use:\n",
    "# combined_data = data1 + data2\n",
    "\n",
    "# Write the combined data to a new JSON file\n",
    "with open('Data/data_part5.json', 'w') as f:\n",
    "    json.dump(combined_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c09c5f1-e546-493b-8ba1-4236e77040e0",
   "metadata": {},
   "source": [
    "## Randomly print a datapoint for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66a1c53-f924-4973-ba19-20051b4dbb24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3119dcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('Data/data_part5.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ead925f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic ADX - [The Pine Guru]\n",
      "Dynamic ADX by The Pine Guru\n",
      "\n",
      "What is the Dynamic ADX?\n",
      "The Dynamic ADX is an indicator created using the regular ADX, Line, and additional ADX Moving Average. This MA allows the script to calculate the ADX differently to the original ADX, providing greater input and accessibility to the user. As the ADX is a volatility indicator, it is communicates to trend strength in the markets. The Dynamic ADX displays these trending Periods through user controlled visualizers like Fills, Background Color, and Bar Color.\n",
      "\n",
      "How do I use the Dynamic ADX?\n",
      "This indicator has 4 different \"versions\" or \"conditions\" in which it displays trend strength. These are achieved by checking and unchecking ADX, ADX MA and Line. Different combinations of these 3 inputs will result in a change of true condition that the script outputs.\n",
      "Dynamic ADX Achieved by checking the ADX and ADX MA, results in an ADX similar to an MA Crossover, with the ADX being over the MA indicating a true or strong trend condition.\n",
      "Regular ADX Achieved by Checking the ADX and Line. Results in the regular calculation of the ADX.\n",
      "Mixture Achieved by Checking all three sections, which results in the calculation a normal ADX as well as the MA. Provides and extra condition or confluence into the ADX.\n",
      "MA and Line Achieved by checking the ADX MA and Line. Results in a similar calculation to an original ADX but with a smoother MA.\n",
      "\n",
      "Recommendations\n",
      "This indicator will work typically in all markets with high volume and volatility. It is recommended that it is used as a confluence in a trading system, and not as an outright indicator. As always do your own testing before live use with this indicator. Do your own Research and refinements.\n",
      "\n",
      "Please Leave a like if you enjoy this Indicator\n",
      "//@version=5\n",
      "indicator(\"Dynamic ADX - [The Pine Guru]\", format=format.price, precision=2)\n",
      "\n",
      "\n",
      "// INPUTS\n",
      "\n",
      "adxop  = input.bool     (true,      title='ADX', group=\"ADX Settings\", inline=\"1\")\n",
      "adxtim = input.timeframe(\"\",        title=\"\",    group=\"ADX Settings\", inline=\"1\")\n",
      "adxlen = input.int      (14,        title=\"\",    group=\"ADX Settings\", inline=\"1\")\n",
      "adxcol = input.color    (color.red, title=\"\",    group=\"ADX Settings\", inline=\"1\")\n",
      "\n",
      "adxmaop  = input.bool     (true,       title=\"ADX MA\", group=\"ADX Settings\", inline=\"2\")\n",
      "adxmatim = input.timeframe(\"\",         title=\"\",       group=\"ADX Settings\", inline=\"2\")\n",
      "adxmalen = input.int      (14,         title=\" \",      group=\"ADX Settings\", inline=\"2\")\n",
      "adxmacol = input.color    (color.blue, title=\"\",       group=\"ADX Settings\", inline=\"2\")\n",
      "\n",
      "adxlineop = input.bool (true,        title=\"ADX Line\", group=\"ADX Settings\", inline=\"3\")\n",
      "adxline   = input.int  (25,          title=\"\",         group=\"ADX Settings\", inline=\"3\")\n",
      "adxlineco = input.color(color.black, title=\"\",         group=\"ADX Settings\", inline=\"3\")\n",
      "\n",
      "adxfilop = input.bool (true,                      title=\"Colour Fill\", group=\"Extra Visuals\", inline=\"4\")\n",
      "adxfilco = input.color(color.new(color.aqua, 40), title=\"\",            group=\"Extra Visuals\", inline=\"4\")\n",
      "\n",
      "adxbarop = input.bool (true,        title=\"Bar Colour\", group=\"Extra Visuals\", inline=\"5\")\n",
      "adxbacol = input.color(color.aqua,  title=\"\",           group=\"Extra Visuals\", inline=\"5\")\n",
      "\n",
      "adxbgop  = input.bool (true,                      title=\"Background Colour\", group=\"Extra Visuals\", inline=\"6\")\n",
      "adxbgcol = input.color(color.new(color.aqua, 75), title=\"\",                  group=\"Extra Visuals\", inline=\"6\")\n",
      "\n",
      "de = input.string(\"==========>\", title=\"See Tool Tip for Script Information\", group=\"Script Information\", tooltip=\"This Script is created using a nomral ADX, an Average of that ADX and a Line. By changing the checked and unchecked combinations of said ADX, MA and Line, you are changing the conditions for how the script interprets a true condition. There are four said combinations in this script, which include a normal ADX (only check ADX and Line), a Dynamic Adx (only check ADX and ADX MA), A mixture (Everything Checked), and a MA ADX (Only Check ADX MA and Line). For more information please see the script info on [The Pine Guru's] Page\")\n",
      "\n",
      "// ADX CALCULATIONS\n",
      "\n",
      "dilen=14\n",
      "\n",
      "dirmov(len) =>\n",
      "\tup = ta.change(high)\n",
      "\tdown = -ta.change(low)\n",
      "\tplusDM = na(up) ? na : (up > down and up > 0 ? up : 0)\n",
      "\tminusDM = na(down) ? na : (down > up and down > 0 ? down : 0)\n",
      "\ttruerange = ta.rma(ta.tr, len)\n",
      "\tplus = fixnan(100 * ta.rma(plusDM, len) / truerange)\n",
      "\tminus = fixnan(100 * ta.rma(minusDM, len) / truerange)\n",
      "\t[plus, minus]\n",
      "adx(dilen, adxlen) =>\n",
      "\t[plus, minus] = dirmov(14)\n",
      "\tsum = plus + minus\n",
      "\tadx = 100 * ta.rma(math.abs(plus - minus) / (sum == 0 ? 1 : sum), adxlen)\n",
      "sig1 = adx(dilen, adxlen)\n",
      "sig = request.security(syminfo.tickerid, adxtim, sig1)\n",
      "\n",
      "adxma1 = ta.ema(sig, adxmalen)\n",
      "adxma  = request.security(syminfo.tickerid, adxmatim, adxma1)\n",
      "\n",
      "// VERSIONS\n",
      "a = adxmaop   and adxop     and adxlineop == false\n",
      "b = adxmaop   and adxlineop and adxop \n",
      "c = adxlineop and adxop     and adxmaop   == false\n",
      "d = adxlineop and adxmaop   and adxop     == false\n",
      "\n",
      "// COLOUR OUTS AND OPS\n",
      "adxout       = adxop     ? adxcol    : na\n",
      "adxmaout     = adxmaop   ? adxmacol  : na\n",
      "adxlineout   = adxlineop ? adxlineco : na\n",
      "fillout      = adxfilop  ? adxfilco  : na\n",
      "bgcolorout   = adxbgop   ? adxbgcol  : na\n",
      "barcolourout = adxbarop  ? adxbacol  : na\n",
      "\n",
      "fill1 = a and sig > adxma ? fillout : na\n",
      "fill2 = b == true and sig > adxma and sig > adxline ? fillout : na\n",
      "fill3 = c and sig > adxline ? fillout : na\n",
      "fill4 = d and adxma > adxline ? fillout : na\n",
      "\n",
      "bg1 = a and sig > adxma ? bgcolorout : na\n",
      "bg2 = b == true and sig > adxma and sig > adxline ? bgcolorout : na\n",
      "bg3 = c and sig > adxline ? bgcolorout : na\n",
      "bg4 = d and adxma > adxline ? bgcolorout : na\n",
      "\n",
      "bc1 = a and sig > adxma ? barcolourout : na\n",
      "bc2 = b == true and sig > adxma and sig > adxline ? barcolourout : na\n",
      "bc3 = c and sig > adxline ? barcolourout : na\n",
      "bc4 = d and adxma > adxline ? barcolourout : na\n",
      "\n",
      "// PLOTS\n",
      "\n",
      "p1 = plot(sig,     color=adxout,     title=\"ADX\")\n",
      "p2 = plot(adxma,   color=adxmaout,   title=\"ADX MA\")\n",
      "p3 = plot(adxline, color=adxlineout, title=\"ADX Line\")\n",
      "\n",
      "fill(p1, p2, fill1, title=\"Fill 1\")\n",
      "fill(p1, p2, fill2, title=\"Fill 2\")\n",
      "fill(p1, p3, fill3, title=\"Fill 3\")\n",
      "fill(p2, p3, fill4, title=\"Fill 4\")\n",
      "\n",
      "barcolor(bc1, title=\"Bar Colour 1\")\n",
      "barcolor(bc2, title=\"Bar Colour 2\")\n",
      "barcolor(bc3, title=\"Bar Colour 3\")\n",
      "barcolor(bc4, title=\"Bar Colour 4\")\n",
      "\n",
      "bgcolor(bg1, title=\"Background Colour 1\")\n",
      "bgcolor(bg2, title=\"Background Colour 2\")\n",
      "bgcolor(bg3, title=\"Background Colour 3\")\n",
      "bgcolor(bg4, title=\"Background Colour 4\")\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "rand_int = random.randint(0, 1799)\n",
    "Indicator_dict = data[rand_int]\n",
    "print(Indicator_dict[\"Indicator Name\"])\n",
    "print(Indicator_dict[\"Indicator Description\"])\n",
    "print(Indicator_dict[\"Indicator Code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e14644f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a539d448",
   "metadata": {},
   "outputs": [],
   "source": [
    "len"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
